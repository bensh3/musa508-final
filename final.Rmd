---
title: "MUSA 508 Final"
description: |
  Analyzing delays on New Jersey Transit & Amtrak
date: "2021-10-22"
author:
  - name: "Benjamin She"
    url: https://github.com/bensh3/
  - name: "Lechuan Huang"
    url: https://github.com/hlechuan/
output:
  distill::distill_article:
    toc: true
    toc_float: true
    code_folding: true
editor_options: 
  markdown: 
  wrap: sentence
  chunk_output_type: inline
---
  <style>
  html {
    scroll-behavior: smooth;
  }
d-article {
  contain: none;
}
#TOC {
position: fixed;
top: 10px;
left: 10px;
padding: 10px;
text-align: right;
inline-size: 250px;
overflow-wrap: break-word;
}

@media screen and (max-width: 900px) {
  #TOC {
  position: relative;
}
}
</style>

## Setup

```{r knitr_opts, include = FALSE}
knitr::opts_chunk$set(fig.path = 'figs/',
                      echo = TRUE, warning = FALSE, message = FALSE, cache.lazy = FALSE)
```

```{r}
library(caret)
library(data.table)
library(gganimate)
library(gridExtra)
library(hms)
library(lubridate)
library(patchwork)
library(riem)
library(scales)
library(sf)
library(tidyverse)
library(tidytransit)

source("https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/functions.r")
```

```{r define time periods}
int.ampeak <- interval(as_hms("06:00:00"),as_hms("10:00:00"))
int.midday <- interval(as_hms("10:00:01"),as_hms("16:00:00"))
int.pmpeak <- interval(as_hms("16:00:01"),as_hms("19:00:00"))
int.evening <- interval(as_hms("19:00:01"),as_hms("23:59:59"))
int.overngt <- interval(as_hms("00:00:00"),as_hms("05:59:59"))
```

## Kaggle data wrangling

```{r intake delay data, echo=FALSE, message=FALSE}
invalid <- rbind(read_csv("delay/invalid_trains.csv"),read_csv("delay/invalid_trains_05-01-19_05-18-20.csv"))
invalid$date <- invalid$date %>% str_replace_all("_","-") %>% as.Date()

delay_files <- list.files("delay",pattern="^20")
delay <- lapply(paste0('delay/',delay_files),read_csv) %>% 
  map(anti_join,invalid,by=c("date","train_id"))

names(delay) <- stringr::str_replace(delay_files, pattern = ".csv", replacement = "")
```

```{r intake GTFS data}
njt <- read_gtfs("gtfs_njt.zip")
njt_sf <- gtfs_as_sf(njt)

amtk <- read_gtfs("gtfs_amtk.zip") %>% filter_feed_by_stops(stop_ids=c('NWK'))
amtk_sf <- gtfs_as_sf(amtk)
```

```{r 2019 NEC line delay data}
necl2019 <- rbindlist(delay %>% tidyselect:::select(starts_with('2019'))) %>% 
  filter(type == 'NJ Transit' & line == 'Northeast Corrdr') %>% 
  arrange(date,train_id,stop_sequence) %>% 
  filter(complete.cases(.)) %>% mutate(period = case_when(
      ymd_hms(paste0('1970-01-01',str_sub(scheduled_time,12))) %within% int.ampeak  ~ "AM peak",
      ymd_hms(paste0('1970-01-01',str_sub(scheduled_time,12))) %within% int.midday  ~ "Midday",
      ymd_hms(paste0('1970-01-01',str_sub(scheduled_time,12))) %within% int.pmpeak  ~ "PM peak",
      ymd_hms(paste0('1970-01-01',str_sub(scheduled_time,12))) %within% int.evening  ~ "Evening",
      ymd_hms(paste0('1970-01-01',str_sub(scheduled_time,12))) %within% int.overngt  ~ "Overnight"
  )) %>% mutate(isWkdy = ifelse(wday(date) %in% c(2,3,4,5,6),TRUE,FALSE)
   ) %>% mutate(direction = case_when(
    stop_sequence == 1 & from != 'New York Penn Station' ~ 'eastbound',
    stop_sequence == 1 & from == 'New York Penn Station' ~ 'westbound'
  )) %>% fill(direction) %>% 
  mutate(stop_seq_abs = case_when(
    from == "Trenton" & direction == 'eastbound' ~ 1,
    from == "Hamilton" & direction == 'eastbound' ~ 2,
    from == "Princeton Junction" & direction == 'eastbound' ~ 3,
    from == "Jersey Avenue" & direction == 'eastbound' ~ 4,
    from == "New Brunswick" & direction == 'eastbound' ~ 5,
    from == "Edison" & direction == 'eastbound' ~ 6,
    from == "Metuchen" & direction == 'eastbound' ~ 7,
    from == "Metropark" & direction == 'eastbound' ~ 8,
    from == "Rahway" & direction == 'eastbound' ~ 9,
    from == "Linden" & direction == 'eastbound' ~ 10,
    from == "Elizabeth" & direction == 'eastbound' ~ 11,
    from == "North Elizabeth" & direction == 'eastbound' ~ 12,
    from == "Newark Airport" & direction == 'eastbound' ~ 13,
    from == "Newark Penn Station" & direction == 'eastbound' ~ 14,
    from == "Secaucus Upper Lvl" & direction == 'eastbound' ~ 15,
    from == "New York Penn Station" & direction == 'eastbound' ~ 16,
    from == "Trenton" & direction == 'westbound' ~ 16,
    from == "Hamilton" & direction == 'westbound' ~ 15,
    from == "Princeton Junction" & direction == 'westbound' ~ 14,
    from == "Jersey Avenue" & direction == 'westbound' ~ 13,
    from == "New Brunswick" & direction == 'westbound' ~ 12,
    from == "Edison" & direction == 'westbound' ~ 11,
    from == "Metuchen" & direction == 'westbound' ~ 10,
    from == "Metropark" & direction == 'westbound' ~ 9,
    from == "Rahway" & direction == 'westbound' ~ 8,
    from == "Linden" & direction == 'westbound' ~ 7,
    from == "Elizabeth" & direction == 'westbound' ~ 6,
    from == "North Elizabeth" & direction == 'westbound' ~ 5,
    from == "Newark Airport" & direction == 'westbound' ~ 4,
    from == "Newark Penn Station" & direction == 'westbound' ~ 3,
    from == "Secaucus Upper Lvl" & direction == 'westbound' ~ 2,
    from == "New York Penn Station" & direction == 'westbound' ~ 1,
  )) 
```

```{r get unique train IDs per day}
# necl.oneday <- necl2019 %>% 
#   filter(date %in% seq(as.Date("2019/06/18"), by = "day", length.out = 1))

necl.id <- necl2019 %>% distinct(train_id,date,direction)
```

## Visualization

### Schedule deviance chart, faceted by time/direction of service

```{r schedule deviance summarise by time period, fig.width=8, fig.height=5}
p1 <- necl2019 %>% filter(isWkdy) %>% group_by(direction,period,stop_seq_abs) %>%
  summarise(avgdelay = mean(delay_minutes)) %>% 
  ggplot(aes(x=stop_seq_abs, y=avgdelay)) +
  geom_line() +
  facet_grid(direction ~ factor(period,levels=c("AM peak","Midday","PM peak","Evening","Overnight"))) +
  ggtitle('Weekday')
p2 <- necl2019 %>% filter(!isWkdy) %>% group_by(direction,period,stop_seq_abs) %>%
  summarise(avgdelay = mean(delay_minutes)) %>% 
  ggplot(aes(x=stop_seq_abs, y=avgdelay)) +
  geom_line() +
  facet_grid(direction ~ factor(period,levels=c("AM peak","Midday","PM peak","Evening","Overnight"))) +
  ggtitle('Weekend')

p1 / p2
```

### Stringline diagram of one day's service

```{r stringline diagram, fig.width=8, fig.height=4}
necl2019 <- necl2019 %>% 
  mutate(to.dist.mp = case_when(
    to == "Trenton" ~ 58.1,
    to == "Hamilton" ~ 54.4,
    to == "Princeton Junction" ~ 48.4,
    to == "Jersey Avenue" ~ 34.4,
    to == "New Brunswick" ~ 32.7,
    to == "Edison" ~ 30.3,
    to == "Metuchen" ~ 27.1,
    to == "Metropark" ~ 24.6,
    to == "Rahway" ~ 20.7,
    to == "Linden" ~ 18.6,
    to == "Elizabeth" ~ 15.4,
    to == "North Elizabeth" ~ 14.4,
    to == "Newark Airport" ~ 12.6,
    to == "Newark Penn Station" ~ 10,
    to == "Secaucus Upper Lvl" ~ 4.9,
    to == "New York Penn Station" ~ 0,
  ),from.dist.mp = case_when(
    from == "Trenton" ~ 58.1,
    from == "Hamilton" ~ 54.4,
    from == "Princeton Junction" ~ 48.4,
    from == "Jersey Avenue" ~ 34.4,
    from == "New Brunswick" ~ 32.7,
    from == "Edison" ~ 30.3,
    from == "Metuchen" ~ 27.1,
    from == "Metropark" ~ 24.6,
    from == "Rahway" ~ 20.7,
    from == "Linden" ~ 18.6,
    from == "Elizabeth" ~ 15.4,
    from == "North Elizabeth" ~ 14.4,
    from == "Newark Airport" ~ 12.6,
    from == "Newark Penn Station" ~ 10,
    from == "Secaucus Upper Lvl" ~ 4.9,
    from == "New York Penn Station" ~ 0,
  ),inter.dist.mp = abs(from.dist.mp-to.dist.mp))

oneday <- necl2019 %>% filter(date %in% slice_sample(.))

oneday %>% 
  ggplot(aes(y=to.dist.mp,group=train_id,color=direction)) +
    geom_line(aes(x=scheduled_time),linetype='dashed') +
    geom_line(aes(x=actual_time)) +
    scale_y_continuous(breaks = oneday$to.dist.mp, labels = oneday$to, minor_breaks = NULL) +
    scale_x_datetime(date_breaks = "1 hour", labels = date_format("%H:%M")) +
    labs(x='Time',y='Station (by milepost distance)',
         title="Northeast Corridor Line stringline diagram",
         subtitle=paste("on sample date",oneday$date,"| Dashed is scheduled time, solid is actual time")) +
    theme(legend.position='none') +
    facet_grid(rows=vars(direction))
```

## Feature engineering

### Weather

```{r weather}
weather.DataNWK <- 
  riem_measures(station = "EWR", date_start = "2019-03-01", date_end = "2019-10-31")

weather.PanelNWK <-  
  weather.DataNWK %>%
  mutate_if(is.character, list(~replace(as.character(.), is.na(.), "0"))) %>% 
  replace(is.na(.), 0) %>%
  mutate(interval60 = ymd_h(substr(valid, 1, 13))) %>%
  mutate(week = week(interval60),
         dotw = wday(interval60, label=TRUE)) %>%
  group_by(interval60) %>%
  summarize(Temperature = max(tmpf),
            Precipitation = sum(p01i),
            Rel_Humidity = mean(relh),
            Wind_Speed = max(sknt)) %>%
  mutate(Temperature = ifelse(Temperature == 0, 42, Temperature))

grid.arrange(top = "Weather Data - Newark, NJ - March-October 2019",
             ggplot(weather.PanelNWK, aes(interval60,Temperature)) + geom_line() + 
               labs(title="Temperature", x="Hour", y="Temperature"),
             ggplot(weather.PanelNWK, aes(interval60,Precipitation)) + geom_line() + 
               labs(title="Percipitation", x="Hour", y="Percipitation"),
             ggplot(weather.PanelNWK, aes(interval60,Rel_Humidity)) + geom_line() + 
               labs(title="Relative humidity", x="Hour", y="Relative humidity"),
             ggplot(weather.PanelNWK, aes(interval60,Wind_Speed)) + geom_line() + 
               labs(title="Wind Speed", x="Hour", y="Wind Speed"))
```

```{r weather join}
necl2019 <- necl2019 %>%
  mutate(interval30 = floor_date(scheduled_time, unit = "30min"),
         interval60 = floor_date(scheduled_time, unit = "hour"),
         week = week(scheduled_time),
         dotw = wday(scheduled_time),
         trip_count = 1) %>%
  left_join(weather.PanelNWK, by = "interval60")%>%
  na.omit()
```

### Cancelled trains data

There is a labor activities in June 2019. https://www.nj.com/traffic/2019/06/nj-transit-engineers-refuse-to-work-ot-as-part-of-dispute-your-commute-will-get-worse.html 

```{r cancelled trains}
cancel <- read_csv("cancel/RAIL_NEC_CANCELLATIONS_DATA.csv") %>%
  filter(YEAR==2019) %>% mutate(CANCEL_COUNT = as.numeric(CANCEL_COUNT),CANCEL_TOTAL = as.numeric(CANCEL_TOTAL))

ggplot(cancel, aes(fill=CATEGORY,y=CANCEL_COUNT, x=factor(str_to_sentence(cancel$MONTH), level=month.name))) + 
    geom_bar(position="fill", stat="identity")+
    scale_y_continuous(labels = scales::percent_format())

cancel <- cancel %>% select(-CANCEL_PERCENTAGE) %>% 
  pivot_wider(names_from=CATEGORY,values_from=CANCEL_COUNT)

necl2019 <- necl2019 %>% mutate(MONTH=str_to_upper(month(date, label=T, abbr=F))) %>% 
  left_join(cancel,by=('MONTH')) %>% mutate_if(is.numeric,coalesce,0) %>% 
  mutate(MONTH = factor(str_to_sentence(MONTH), level=month.name))
```

## Prepare model

```{r time lags}
necl2019 <- necl2019 %>% 
  arrange(from,interval30) %>% 
  mutate(lag30Min = dplyr::lag(delay_minutes,1),
         lag1Hour = dplyr::lag(delay_minutes,2),
         lag90Min = dplyr::lag(delay_minutes,3),
         lag2Hour = dplyr::lag(delay_minutes,4),
         lag3Hour = dplyr::lag(delay_minutes,6),
         lag12Hour = dplyr::lag(delay_minutes,24),
         lag1Day = dplyr::lag(delay_minutes,48)
  )
```

```{r evaluate_lags, cache = TRUE, warning = FALSE, message = FALSE}
as.data.frame(necl2019) %>%
    group_by(interval30) %>% 
    summarise_at(vars(starts_with("lag"), "delay_minutes"), mean, na.rm = TRUE) %>%
    gather(Variable, Value, -interval30, -delay_minutes) %>%
    mutate(Variable = factor(Variable, levels=c("lag30Min","lag1Hour","lag90Min","lag2Hour",
                                                "lag3Hour","lag12Hour","lag1Day")))%>%
    group_by(Variable) %>%  
    summarize(correlation = round(cor(Value, delay_minutes),2))
```


## Regression model training

```{r train_test, cache = TRUE}
delay.Train <- filter(necl2019, month(date) > 4)
delay.Test <- filter(necl2019, month(date) <= 4)
```

## Regression formula

```{r}
fit <- lm(delay_minutes ~ to + period + isWkdy + direction + Precipitation +
            CANCEL_TOTAL + AMTRAK + `Crew/Engineer Availability` + 
            `Equipment Availability` + Mechanical + inter.dist.mp +
            lag30Min + lag1Hour + lag90Min + lag2Hour + lag3Hour + lag12Hour,
data=delay.Train)
```

```{r stargazer, results='asis'}
stargazer::stargazer(fit, type='html', align=TRUE, no.space=TRUE)
```


## Predictions on test data

```{r nest_data, message=FALSE, warning=FALSE, cache=TRUE}
delay.Test.weekNest <- 
  delay.Test %>%
  nest(-week)
```

```{r predict_function, cache = TRUE}
model_pred <- function(dat, fit){
   pred <- predict(fit, newdata = dat)}
```

```{r do_predicitons, cache=FALSE}
week_predictions <- 
  delay.Test.weekNest %>% 
    mutate(model = map(.x = data, fit = fit, .f = model_pred)) %>% 
    gather(Regression, Prediction, -data, -week) %>%
    mutate(Observed = map(.data, pull, delay_minutes),
           Absolute_Error = map2(Observed, Prediction,  ~ abs(.x - .y)),
           MAE = map_dbl(Absolute_Error, mean, na.rm = TRUE),
           sd_AE = map_dbl(Absolute_Error, sd, na.rm = TRUE))

```

```{r plot_errors_by_model, cache = TRUE}
week_predictions %>%
  dplyr::select(week, Regression, MAE) %>%
  gather(Variable, MAE, -Regression, -week) %>%
  ggplot(aes(week, MAE)) + 
    geom_bar(aes(fill = Regression), position = "dodge", stat="identity") +
    labs(title = "Mean Absolute Errors by week")
```

```{r error_vs_actual_timeseries, cache = TRUE, warning = FALSE, message = FALSE, fig.width=5}
week_predictions %>% 
    mutate(interval30 = map(data, pull, interval30),
           from = map(data, pull, from),
           direction = map(data,pull,direction)) %>%
    dplyr::select(interval30, from, direction, Observed, Prediction, Regression) %>%
    unnest(cols = c(interval30, from, direction, Observed, Prediction)) %>%
    gather(Variable, Value, -Regression, -interval30, -from, -direction) %>%
    group_by(Regression, Variable, interval30) %>%
    summarize(Value = mean(Value)) %>%
    ggplot(aes(interval30, Value, colour=Variable)) + 
      geom_line(size = 0.5) + 
      facet_wrap(~Regression, ncol=1) +
      labs(title = "Predicted/Observed delay time series",
           subtitle = "Test set of three weeks",  x = "Hour", y= "Delay (minutes)") +
    theme(legend.position='bottom')
```

## Cross-validation

```{r}
```


## Conclusion

```{r}

```



